import torch

class AudioFrameWinSize:
    """
    æ ¹æ®è¾“å…¥çš„éŸ³é¢‘ç‰¹å¾ Tensor è‡ªåŠ¨è®¡ç®—åˆé€‚çš„æ»‘åŠ¨çª—å£å¸§æ•°ï¼ˆt å€¼ï¼‰ã€‚
    ä¸»è¦ç”¨äºè§£å†³ WanVideo æ¨¡å‹ä¸­å›  t ä¸åŒ¹é…å¯¼è‡´çš„ shape mismatch æŠ¥é”™ï¼š
        b (t n) c -> (b t) n c
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "input_tensor": ("TENSOR",),
                "max_t": ("INT", {"default": 200, "min": 1, "max": 1000}),
                "tolerance": ("INT", {"default": 3, "min": 0, "max": 50}),
            }
        }

    RETURN_TYPES = ("INT",)
    RETURN_NAMES = ("frame_window_t",)
    FUNCTION = "process"
    CATEGORY = "WanVideo/éŸ³é¢‘å·¥å…·"

    def process(self, input_tensor: torch.Tensor, max_t: int, tolerance: int) -> tuple:
        # æ£€æŸ¥ tensor ç»´åº¦åˆæ³•æ€§
        if input_tensor.ndim < 2:
            raise ValueError(f"è¾“å…¥ Tensor å½¢çŠ¶æ— æ•ˆ: {input_tensor.shape}")

        seq_len = input_tensor.shape[1]

        # æŸ¥æ‰¾èƒ½æ•´é™¤ seq_len çš„ t å€¼
        valid_t_values = [t for t in range(1, max_t + 1) if seq_len % t == 0]

        if valid_t_values:
            # ä¼˜å…ˆå–æœ€å¤§çš„æ•´é™¤å€¼
            t = valid_t_values[-1]
        else:
            # å®¹å¿å°èŒƒå›´è¯¯å·®ï¼Œä¾‹å¦‚ seq_len=99840, t=73 æ—¶çš„ä½™æ•°
            best_t, min_remainder = 1, seq_len
            for guess in range(1, max_t + 1):
                remainder = seq_len % guess
                if remainder <= tolerance and remainder < min_remainder:
                    best_t = guess
                    min_remainder = remainder
            t = best_t

        print(f"[éŸ³é¢‘æ»‘åŠ¨çª—å£å€¼è®¡ç®—] è¾“å…¥åºåˆ—é•¿åº¦={seq_len}, è®¡ç®—å¾—åˆ° t={t}")
        return (t,)


NODE_CLASS_MAPPINGS = {
    "AudioFrameWinSize": AudioFrameWinSize
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AudioFrameWinSize": "ğŸ§ éŸ³é¢‘æ»‘åŠ¨çª—å£å€¼è®¡ç®—"
}
